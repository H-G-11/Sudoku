{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geological-gauge",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Projet de Reinforcement Learning </p>\n",
    "### <p style=\"text-align: center;\"> Sudoku et Reinforcement Learning </p>\n",
    "\n",
    "#### <div style=\"text-align: right\"> Auteur : Hugues Gallier </div>\n",
    "\n",
    "J'ai souhaité faire ce projet sur un jeu bien connu, aux règles très simples : le jeu du sudoku. Celui-ci remonte à la fin du XIXème siècle en France [[1]](#bibliography) mais a continué de poser de nombreux problèmes mathématiques [[2]](#bibliography) jusqu'à très récemment.\n",
    "En effet, ce n'est que dans les années 2010 [[3]](#bibliography) qu'une équipe de chercheurs prouve la conjecture selon laquelle toute grille de 16 indices ou moins ne possède pas d'unique solution ; cette preuve leur aura nécessité l'équivalent de 7 millions d'heures de CPU afin d'envisager tous les cas possibles.\n",
    "\n",
    "Ce jeu reste aujourd'hui très intéressant afin de tester des approches de Machine Learning ou de Reinforcement Learning. En effet, même si les algorithmes déterministes marchent très bien (l'algorithme Backtrack notamment, pouvant bénéficier d'une optimisation très efficace, voir Dancing Links de Knuth [[4]](#bibliography)), la taille des grilles finales possibles reste très conséquente (environ 6e21, voir de nouveau [[2]](#bibliography)), et ce problème peut être considéré comme un exemple d'application intéressante pour des méthodes de type Reinforcement Learning.\n",
    "\n",
    "Ainsi, je comparerai dans ce notebook plusieurs méthodes en termes de nombre de grilles différentes considérées avant d'aboutir à la solution (ce que j'appelerai **itération** par la suite est le fait de changer de grille considérée pour une nouvelle grille). En effet, le temps d'exécution des différents algorithmes repose sur l'optimisation de ceux-ci et sur les CPU ou GPU utilisées ; le nombre d'itérations, lui, ne repose que sur les méthodes que l'on considère.\n",
    "\n",
    "Ce notebook sera divisé en plusieurs parties:\n",
    "\n",
    "- [Partie I](#partie_1): Algorithme Backtrack\n",
    "- [Partie II](#partie_2): Approche Deep Learning\n",
    "- [Partie III](#partie_3): Monte Carlo Tree Search\n",
    "- [Partie IV](#partie_4): AlphaSudoku: implémentation simplifiée et adaptée au Sudoku d'AlphaGo\n",
    "- [Partie V](#partie_5): Comparaison de ces algorithmes sur 1000 nouvelles grilles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-bangkok",
   "metadata": {},
   "source": [
    "## Introduction : les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-fortune",
   "metadata": {},
   "source": [
    "J'utiliserai tout au long de ce notebook les données présentes [ici](https://www.kaggle.com/radcliffe/3-million-sudoku-puzzles-with-ratings), qui contiennent 3 millions de grilles avec leurs solutions respectives. Ce dataset est intéressant car il contient des grilles difficiles à résoudre, ce qui n'est pas le cas de tous les datasets que j'ai pu trouver. J'ai entraîné le réseau de neurones utilisé dans II et IV sur les 2 premiers millions de lignes, et testé tous les algorithmes sur 700 grilles issues du million suivant (j'ai finalement réussi à faire marcher tous les algorithmes dans un temps raisonnable).\n",
    "\n",
    "Ce dataset contient de plus une indication sur la difficulté des grilles considérées. Cette difficulté est calculée à partir du nombre d'itérations nécessaires en moyenne pour un algorithme de référence à compléter ces grilles. Voir plus d'information [ici](https://www.kaggle.com/radcliffe/3-million-sudoku-puzzles-with-ratings).\n",
    "\n",
    "Voici une idée de la difficulté et du nombre d'indications données pour ces grilles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.getcwd() \n",
    "sys.path.append(os.path.abspath(os.path.join(path, os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"assets/data.csv\")\n",
    "\n",
    "_data_X = data[\"puzzle\"].apply(lambda x : [int(i) if i != '.' else 0 for i in x ])\n",
    "data_X = np.stack(_data_X.to_numpy()).reshape((700, 9, 9))\n",
    "\n",
    "_data_Y = data[\"solution\"].apply(lambda x : [int(i) for i in x])\n",
    "data_Y = np.stack(_data_Y.to_numpy()).reshape((700, 9, 9))\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(pb, solution):\n",
    "    print('Problem                            Solution')\n",
    "    print('+-------+-------+-------+          +-------+-------+-------+')\n",
    "    for i in range(9):\n",
    "        row1 = pb[i]\n",
    "        row2 = solution[i]\n",
    "        to_print = \"| \"\n",
    "        for j in range(9):\n",
    "            to_print += f\"{row1[j] if row1[j] else '.'} \"\n",
    "            if j % 3 == 2:\n",
    "                to_print += f\"| \"\n",
    "        to_print += f\"         | \"\n",
    "        for j in range(9):\n",
    "            to_print += f\"{row2[j]if row2[j] else '.'} \"\n",
    "            if j % 3 == 2:\n",
    "                to_print += f\"| \"\n",
    "        print(to_print)\n",
    "        if i % 3 == 2:\n",
    "            print('+-------+-------+-------+          +-------+-------+-------+')\n",
    "        \n",
    "pretty_print(data_X[0], data_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5), sharey='row')\n",
    "fig.suptitle(\"Description de la difficulté et du nombre d'indications données\")\n",
    "ax1.hist(data['difficulty'])\n",
    "ax1.set_title('Difficulté')\n",
    "ax2.hist(data['clues'], bins=range(21, 28))\n",
    "ax2.set_title(\"Nombre d'indications\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-interface",
   "metadata": {},
   "source": [
    "Il est à noter que la difficulté n'est pas fonction du nombre d'indications données. En effet, certaines gilles peuvent par exemple avoir relativement peu d'indications mais en impliquer directement un grand nombre.\n",
    "\n",
    "Ci-dessous, je télécharge simplement les données issues de mes expériences:\n",
    "- df_iterations contient le nombre d'itérations nécessaires à résoudre chacun des problèmes pour les algorithmes considérés.\n",
    "- df_solved contient le nombre de cases vides à la fin des algorithmes. Un nombre de cases vides différent de 0 indique que l'algorithme n'a pas trouvé la solution du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iterations = pd.read_csv('assets/df_it.csv')\n",
    "df_solved = pd.read_csv('assets/df_so.csv')\n",
    "\n",
    "df_iterations['difficulty'] = df_iterations['difficulty'].apply(round)\n",
    "df_solved['difficulty'] = df_solved['difficulty'].apply(round)\n",
    "\n",
    "df_solved_bool = df_solved[df_solved['difficulty'] < 5].copy()\n",
    "df_solved_bool[[\"Backtrack\", \"MCTS\", \"DeepIterativeSolver\", \"AlphaSudoku\"]] = \\\n",
    "    (df_solved_bool[[\"Backtrack\", \"MCTS\", \"DeepIterativeSolver\", \"AlphaSudoku\"]] > 0 ) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iterations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solved.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-victim",
   "metadata": {},
   "source": [
    "<a id='partie_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-helena",
   "metadata": {},
   "source": [
    "## Partie I: présentation de l'algorithme Backtrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-machinery",
   "metadata": {},
   "source": [
    "L'algorithme Backtrack est l'algorithme le plus simple et le plus efficace afin de résoudre une grille de Sudoku. En effet, celui-ci repose sur l'exploration de coups possibles avec la possibilité de revenir en arrière si on arrive à une impasse.\n",
    "\n",
    "Le bon fonctionnement de cet algorithme repose sur une heuristique le rendant très efficace: lorsque l'on doit choisir une action, il vaut mieux choisir tout d'abord la contrainte à respecter (un chiffre différent sur chaque cellule d'une ligne, d'une colonne ou d'un carré, ou encore le fait que chaque chiffre doit apparaître au moins une fois dans ces ensembles) pouvant être satisfaite par le nombre minimum d'action, puis prendre une action au hasard dans cet ensemble.\n",
    "\n",
    "Dans les faits, c'est ce que tout le monde fait intuitivement. Si une cellule n'a qu'un seul choix, le chiffre 5 par exemple, on mettra le chiffre 5 dans cette celulle avant de faire quoique ce soit d'autre. De même, si toutes les cellules présentes trois choix ou plus et qu'une cellule peut être remplie que par deux chiffres possiblement, on aura tendance à remplir cette dernière en premier. De même, si le chiffre 8 ne peut apparaître qu'une seule fois sur une ligne donnée, on remplira la cellule correspondante avec le chiffre 8 avant de passer à autre chose.\n",
    "\n",
    "Voici deux classes constituant ce premier algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sudoku import SmartGrid\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SudokuGrid:\n",
    "    \"\"\" Represent a Sudoku grid.\n",
    "    \n",
    "    Allows to find possible children (sudoku grids that can be \n",
    "    reached with one legal move), and to compare sudoku grids. \"\"\"\n",
    "\n",
    "    def __init__(self, grid):\n",
    "        \n",
    "        \"\"\" Need a numpy array or a SmartGrid (custom wrapper around\n",
    "        numpy array with useful methods such as possibilities).\n",
    "        Those two wrappers are useful because some solvers won't \n",
    "        use possibilities, so that the calculation of them should\n",
    "        be optional.\"\"\"\n",
    "        \n",
    "        if isinstance(grid, np.ndarray):\n",
    "            grid = SmartGrid.from_grid(grid.copy())\n",
    "        self.grid = grid\n",
    "\n",
    "    def find_children(self):\n",
    "        \"\"\" Find all possible children of this sudoku grid. \"\"\"\n",
    "        \n",
    "        if self.is_terminal():\n",
    "            return set()\n",
    "        else:\n",
    "            possible_moves = []\n",
    "            pos = self.grid.possibilities\n",
    "            min_nb_pos_ind = min([len(v) for v in pos.values()])\n",
    "            for index in pos:\n",
    "                # just look at indeces with min pos\n",
    "                if len(pos[index]) == min_nb_pos_ind:\n",
    "                    for value in pos[index]:\n",
    "                        possible_moves.append((index, value))\n",
    "                    # we just return children on 1 cell --> sufficient\n",
    "                    return {self.take_action(a[0], a[1])\n",
    "                            for a in possible_moves}\n",
    "\n",
    "    def find_random_child(self):\n",
    "        \"\"\" Find a random child of this grid. Respect heuristic given\n",
    "        before. \"\"\"\n",
    "        \n",
    "        pos = self.grid.possibilities\n",
    "        min_nb_pos_ind = min([len(v) for v in pos.values()])\n",
    "        if len(pos) == 0 or min_nb_pos_ind == 0:\n",
    "            return None\n",
    "        pos_considered = []\n",
    "        for k, v in pos.items():\n",
    "            # just look at indeces with min pos\n",
    "            if len(v) == min_nb_pos_ind:\n",
    "                pos_considered.append(k)\n",
    "        index = random.choice(pos_considered)\n",
    "        action = random.choice(self.grid.possibilities[index])\n",
    "        child = self.take_action(index, action)\n",
    "        return child\n",
    "\n",
    "    def take_action(self, index, action):\n",
    "        \"\"\" Fill a cell and return a new SudokuGrid. \"\"\"\n",
    "        \n",
    "        new_grid = SudokuGrid(self.grid.grid.copy())\n",
    "        new_grid.grid.fill_cell(*index, action)\n",
    "        return new_grid\n",
    "\n",
    "    def is_terminal(self):\n",
    "        \"\"\" Check if this sudoku grid is terminal. \"\"\"\n",
    "        \n",
    "        # if no possibilities\n",
    "        if len(self.grid.possibilities) == 0:\n",
    "            return True\n",
    "        # if it is complete or incorrect or that a cell can't be filled\n",
    "        elif self.grid.is_complete() or not self.grid.is_correct() or \\\n",
    "                min([len(v) for v in self.grid.possibilities.values()]) == 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def reward(self):\n",
    "        \"\"\" Return reward associated to this gris when it is terminal.\n",
    "        \n",
    "        It is simply the proportion of filled cells. \"\"\"\n",
    "        \n",
    "        return np.count_nonzero(self.grid.grid) / 81\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\" Hash will be useful to use objects of this class\n",
    "        as key of dictionaries. \"\"\"\n",
    "        \n",
    "        return hash(str(self.grid.grid))\n",
    "\n",
    "    def __eq__(self, grid2):\n",
    "        if np.array_equal(self.grid.grid, grid2.grid.grid):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.grid.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class BacktrackSolver:\n",
    "    \"\"\" Implement a Backtrack Solver. \"\"\"\n",
    "\n",
    "    def __init__(self, sudoku_grid):\n",
    "        \"\"\" Input:\n",
    "        sudoku_grid: either a numpy array or a SudokuGrid object.\n",
    "        Numpy array will be converted to SudokuGrid. \"\"\"\n",
    "        if isinstance(sudoku_grid, np.ndarray):\n",
    "            sudoku_grid = SudokuGrid(sudoku_grid)\n",
    "        assert isinstance(sudoku_grid, SudokuGrid), \\\n",
    "            \"Please enter an numpy array or a SudokuGrid object.\"\n",
    "        self.iterations = 0\n",
    "        self.sudoku_grid = sudoku_grid\n",
    "        self.history = [sudoku_grid]\n",
    "        self.children = {}\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\" Choose action while not solved. \"\"\"\n",
    "        while not self.sudoku_grid.grid.is_complete():\n",
    "            self.sudoku_grid = self.choose_action()\n",
    "            self.iterations += 1\n",
    "        return self.sudoku_grid\n",
    "\n",
    "    def choose_action(self):\n",
    "        \"\"\" Choose action forward (fill) or backward (erase).\n",
    "        \n",
    "        Both actions will result in an iteration being counted, since going\n",
    "        backward implies storing all grids or recalculating all possibilities\n",
    "        which are both costly. \"\"\"\n",
    "\n",
    "        if self.sudoku_grid not in self.children:\n",
    "            self.children[self.sudoku_grid] = self.sudoku_grid.find_children()\n",
    "            if len(self.children[self.sudoku_grid]) == 0:\n",
    "                return self.sudoku_grid\n",
    "            new_grid = self.children[self.sudoku_grid].pop()\n",
    "            self.history.append(new_grid)\n",
    "            return new_grid\n",
    "\n",
    "        if len(self.children[self.sudoku_grid]) == 0:\n",
    "            if len(self.history) == 0:\n",
    "                raise RuntimeError(\"Solver failed\")\n",
    "            return self.history.pop()\n",
    "\n",
    "        new_grid = self.children[self.sudoku_grid].pop()\n",
    "        self.history.append(new_grid)\n",
    "        return new_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-religious",
   "metadata": {},
   "source": [
    "#### Résultats Backtrack\n",
    "\n",
    "Vous pouvez voir ci-dessous les performances de cet algorithme sur les grilles testées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Description des performances de l'algorithme BackTrack\")\n",
    "axes[0].boxplot(df_iterations[\"Backtrack\"])\n",
    "axes[0].set_title(\"Nombre d'itérations effectuées\")\n",
    "axes[0].set_ylim((0, 10000))\n",
    "df_iterations[df_iterations['difficulty'] < 5].groupby(\"difficulty\")['Backtrack'].apply(np.mean).plot.bar(rot=0)\n",
    "axes[1].set_title(\"Moyenne itérations effectuées par niveau de difficulté\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks([1], ['Backtrack Algorithm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-blair",
   "metadata": {},
   "source": [
    "<a id='partie_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-glossary",
   "metadata": {},
   "source": [
    "## Partie II: Approche Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-church",
   "metadata": {},
   "source": [
    "L'idée de cette partie est d'entraîner un réseau de neurones convolutionnel profond à prédire la solution d'une grille de Sudoku à partir du problème initial:\n",
    "- les données en entrée et en sortie sont au format (9, 9, 9) : en effet, la première dimension est le nombre de channels de la grille initiale, avec un channel par valeur. Le channel i sera constitué de 1 là où il y a la valeur i + 1 sur la grille et de 0 partout ailleurs. Vous pouvez voir ci-dessous l'encoder construit pour transformer les grilles (9, 9) en ce nouveau format.\n",
    "- la loss utilisée est une cross-entropy généralisée, car le format précédent nous permet de prédire les probabilités associées aux 9 classes possibles pour chaque cellule donnée.\n",
    "- j'ai dû redéfinir une softmax afin de pouvoir respecter le format de mes données.\n",
    "- le réseau est constitué de 8 couches de convolutions avec des noyaux au format (9, 1), (1, 9), (3, 3) et (9, 9) pour la première couche (le noyau (9, 9) est tout de même utile car je prends un padding 'same' afin de garder la dimension ; empiriquement, ajouter ce noyau améliorait les résultats) ; des noyaux plus classiques sont utilisés ensuite, avec une skip connection ajoutée sur l'avant-dernière couche, la reliant avec les entrées (afin de faciliter la tâche pour que le réseau prédise bien les bonnes valeurs lorsqu'elles sont données en entrée dans le problème initial). Le réseau ainsi obtenu a 1 million de paramètres.\n",
    "\n",
    "Ce réseau sera également utilisé dans la partie IV.\n",
    "\n",
    "Quant à l'algorithme utilisant uniquement cette approche Deep Learning, il est proposé à la suite de la présentation du réseau. Il consiste simplement à prédire les cellules une par une au lieu de les prédire toutes d'un coup.\n",
    "\n",
    "Note: j'aurais pu obtenir un réseau plus performant en tirant partie de la symétrie du jeu, et en l'entraînant sur des grilles avec des nombres d'indices plus variés (allant de 20 à 70 par exemple, alors qu'ici je garde les grilles entre 20 et 26 environ). J'ai préféré me concentrer sur l'implémentation des algorithmes en eux-mêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encoder(array_of_grids):\n",
    "    \"\"\" Transform numpy array of sudoku grids in one hot\n",
    "    array of dimension (len(arr), 9, 9, 9), with one channel\n",
    "    for each value from 1 to 9. \"\"\"\n",
    "\n",
    "    if len(array_of_grids.shape) == 2:\n",
    "        array_of_grids = np.array([array_of_grids])\n",
    "    shape_encoded = (*array_of_grids.shape, 9)\n",
    "    encoded = np.zeros(shape_encoded, dtype=np.bool)\n",
    "    for i, grid in enumerate(array_of_grids):\n",
    "        for value in range(9):\n",
    "            encoded[i][value] = (grid == value + 1) * 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import math, exp\n",
    "\n",
    "class SoftmaxMap(layers.Layer):\n",
    "    \"\"\" Softmax map to apply a softmax on each index (i, j). \"\"\"\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "        self.axis = axis\n",
    "        super(SoftmaxMap, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        e = exp(x - math.reduce_max(x, axis=self.axis, keepdims=True))\n",
    "        s = math.reduce_sum(e, axis=self.axis, keepdims=True)\n",
    "        return e / s\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-philosophy",
   "metadata": {},
   "source": [
    "Voici le réseau en question. Il contient 1 million de paramètres et s'entraîne en 20 minutes sur les 2 millions de grilles évoquées ci-dessus (sur Colab avec un \"boost\" GPU). Le dataset d'entraînement au format (2000000, 9, 9, 9) rentre très bien dans la RAM à condition de préciser que tous les nombres sont des booléens et non des float.\n",
    "\n",
    "<img src=\"model.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-special",
   "metadata": {},
   "source": [
    "Les performances du réseau étaient d'environ $0.6$ pour la cross-entropie généralisée sur le dataset de test (3ème million de grilles), ce qui correspondait à environ $70 \\%$ des cellules étant prédites de manière correcte. En revanche, presque aucune des grilles de test n'était prédite de manière entièrement correcte directement par le réseau. Il fallait donc tricher un peu et faire remplir les cellules une par une ! De plus, je guide le réseau en lui faisant remplir de manière non probabiliste les cellules ayant une unique possibilité.\n",
    "\n",
    "Cette approche est codée dans l'algorithme suivant, appelé DeepIterativeSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from Sudoku import SmartGrid\n",
    "\n",
    "\n",
    "class DeepIterativeSolver:\n",
    "    \"\"\" At each step, take action with highest probability. \"\"\"\n",
    "\n",
    "    def __init__(self, grid, model=None,\n",
    "                 pathnet='policy_network'):\n",
    "        if isinstance(grid, np.ndarray):\n",
    "            grid = SmartGrid.from_grid(grid.copy())\n",
    "        self.grid = grid\n",
    "        if model is None:\n",
    "            model = load_model(pathnet)\n",
    "        self.model = model\n",
    "        self.iterations = 0\n",
    "\n",
    "    def solve(self):\n",
    "        while not self.grid.is_complete() and self.grid.is_correct():\n",
    "            proba_dict = self._predict_probas()\n",
    "            if proba_dict is None:\n",
    "                print(\"Solver failed\")\n",
    "                return self.grid.grid\n",
    "            selected_action = max(proba_dict, key=proba_dict.get)\n",
    "            self._take_action(selected_action)\n",
    "            self.iterations += 1\n",
    "        return self.grid.grid\n",
    "\n",
    "    def _predict_probas(self):\n",
    "        array_of_proba = self.model.predict(\n",
    "            custom_encoder(self.grid.grid)\n",
    "            )\n",
    "        proba_dict = {}\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if self.grid.grid[i, j] == 0:\n",
    "                    if (i, j) not in self.grid.possibilities:\n",
    "                        return None\n",
    "                    pos_at_index = self.grid.possibilities[(i, j)]\n",
    "                    if len(pos_at_index) == 1:\n",
    "                        proba_dict = {}\n",
    "                        proba_dict[((i, j), pos_at_index[0])] = 1\n",
    "                        return proba_dict\n",
    "                    for v in range(9):\n",
    "                        proba_dict[((i, j), v + 1)] = \\\n",
    "                            array_of_proba[0, v, i, j]\n",
    "\n",
    "        return proba_dict\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        index = action[0]\n",
    "        value = action[1]\n",
    "        self.grid.fill_cell(*index, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-institution",
   "metadata": {},
   "source": [
    "Cet algorithme à un nombre d'itérations quasi-constant pour un temps d'exécution d'une seconde environ, car il ne revient jamais en arrière. En revanche, comme vous pouvez le voir ci-dessous, il échoue souvent ($40 \\%$ des cas) à trouver la bonne solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Analyse des performances de DeepIterativeSolver\")\n",
    "axes[0].bar(x=['Succès', 'Echec'],\n",
    "        height=[100 * (1 - df_solved_bool['DeepIterativeSolver'].mean()),\n",
    "                100 * df_solved_bool['DeepIterativeSolver'].mean()],\n",
    "       width=0.4)\n",
    "axes[0].set_title('Succès vs échecs de DeepIterativeSolver')\n",
    "df_solved_bool.groupby(\"difficulty\")['DeepIterativeSolver'].apply(np.mean).plot.bar(rot=0);\n",
    "axes[1].set_title(\"Taux d'échec en fonction de la difficulté\")\n",
    "plt.sca(axes[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-tissue",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir, cet algorithme est également sensible à la difficulté des grilles ! Cela s'explique par le guidage lorsqu'une unique possibilité se présente. Comme nous pouvons le voir ci-dessous, le taux de succès semble moins lié au nombre d'indices donnés (même si c'est égalenement fortement corrélé) qu'à la difficulté des grilles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solved_bool[(df_solved_bool[\"clues\"] < 28) &\n",
    "                (df_solved_bool[\"clues\"] > 21)].groupby(\"clues\")['DeepIterativeSolver']\\\n",
    "    .apply(np.mean).plot.bar(title=\"Taux d'échec par indices donnés\", rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-rally",
   "metadata": {},
   "source": [
    "<a id='partie_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-dominican",
   "metadata": {},
   "source": [
    "## Partie III: Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-earthquake",
   "metadata": {},
   "source": [
    "Dans cette partie, j'implémente un algorithme de Monte Carlo Tree Search appliqué aux Sudokus.\n",
    "\n",
    "Le principe de cet algorithme est d'explorer différents chemins à partir de l'état auquel on se trouve, en construisant un arbre d'enfants (noeuds) possibles avec pour chacun une valeur associée. Cet arbre est étendu un nombre arbitraire de fois, et les valeurs des noeuds sont calculées en allant jusqu'à un état terminal (en général en-dehors de l'arbre, par _rollout_ ; la _rollout policy_ utilisée ici est basée sur un choix aléatoire respectant l'heuristique donnée dans la partie I), et en faisant remonter la valeur obtenue avec un éventuel facteur de discount (que je fixe à 1 ici). A chaque embranchement de l'arbre, une nouvelle grille est choisie en balançant entre l'exploration et l'exploitation, selon une fonction de choix appelée _Upper Confidence Bounds for Trees_, définie comme la _tree policy_. Le poids théorique d'exploration est de $\\sqrt{2}$, et comme cet algorithme est assez lent, je n'ai pas cherché à optimiser ce poids.\n",
    "\n",
    "La fonction de \"reward\" utilisée ici est très simple et correspond simplement au nombre de cellules remplies dans les grilles terminales:\n",
    "$$r(s, a) = \\frac{nb cellules remplies}{81}$$\n",
    "Je garde un facteur de discount à 1 puisque chaque action est également importante. Empiriquement, ce choix très simple de fonction de reward semble donner de bons résultats, même si un grand nombre de chemins est parfois exploré.\n",
    "\n",
    "De même, je n'ai pas cherché à optimiser le nombre d'expansions de l'arbre considérées à chaque étape avant de choisir une action. Pour mes simulations, je l'ai fixé à 20, mais il faudrait probablement le fixer à 100 ou plus pour obtenir de meilleurs résultats.\n",
    "\n",
    "Comme j'ai déjà pu le dire auparavant, à chaque embranchement, je ne considère que les cellules avec un nombre minimal de possibilités.\n",
    "\n",
    "Note: Je me suis inspiré de [cette implémentation générale](#https://gist.github.com/qpwo/c538c6f73727e254fdc7fab81024f6e1) que j'ai adaptée aux sudokus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log, sqrt\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    \"\"\" MCTS algorithm for Sudoku. \"\"\"\n",
    "\n",
    "    def __init__(self, sudoku_grid, exploration_weight=sqrt(2),\n",
    "                 max_depth_tree=20, max_iterations=10000):\n",
    "        \"\"\" Inputs:\n",
    "        - sudoku_grid: as above, np array of SudokuGrid object\n",
    "        - exploration_weight: to arbitrate between exploration\n",
    "        and exploitation\n",
    "        - max_depth_tree: number of expansions considered before choosing\n",
    "        each action\n",
    "        - max_iterations: if number of iterations exceeded, solver\n",
    "        must have failed. \"\"\"\n",
    "        \n",
    "        if isinstance(sudoku_grid, np.ndarray):\n",
    "            sudoku_grid = SudokuGrid(sudoku_grid)\n",
    "        self.sudoku_grid = sudoku_grid\n",
    "        self.exploration_weight = exploration_weight\n",
    "        self.Q = {}\n",
    "        self.N = {}\n",
    "        self.children = {}\n",
    "        self.max_depth_tree = max_depth_tree\n",
    "        self.iterations = 0\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def solve(self):\n",
    "        while not self.sudoku_grid.is_terminal():\n",
    "            for i in range(self.max_depth_tree):\n",
    "                self.rollout()\n",
    "            self.sudoku_grid = self.choose_best_action()\n",
    "            if self.iterations > self.max_iterations:\n",
    "                print(\"Solver failed\")\n",
    "                break\n",
    "        return self.sudoku_grid\n",
    "\n",
    "    def choose_best_action(self):\n",
    "        \"\"\" From a Sudoku grid, chooses best possible child. \"\"\"\n",
    "        \n",
    "        self.iterations += 1\n",
    "        if self.sudoku_grid.is_terminal():\n",
    "            return self.sudoku_grid\n",
    "\n",
    "        if self.sudoku_grid not in self.children:\n",
    "            return self.sudoku_grid.find_random_child()\n",
    "\n",
    "        def score(n):\n",
    "            \"\"\" Scores possible childs. \"\"\"\n",
    "            if self.N.get(n, 0) == 0:\n",
    "                return -1\n",
    "            return self.Q.get(n, 0) / self.N[n]\n",
    "\n",
    "        if len(self.children[self.sudoku_grid]) == 0:\n",
    "            if self.sudoku_grid.find_random_child() is not None:\n",
    "                return self.sudoku_grid.find_random_child()\n",
    "            else:\n",
    "                return RuntimeError(\"Solver failed\")\n",
    "\n",
    "        return max(self.children[self.sudoku_grid],\n",
    "                   key=score)\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\" From the current tree, expand one layer and then simulate\n",
    "        until an end grid is reached. \"\"\"\n",
    "        path = self._select(self.sudoku_grid)\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "\n",
    "    def _select(self, sudoku_grid):\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(sudoku_grid)\n",
    "            if sudoku_grid not in self.children \\\n",
    "                    or not self.children[sudoku_grid]:\n",
    "                self.iterations += 1\n",
    "                return path\n",
    "            unexplored = self.children[sudoku_grid] - self.children.keys()\n",
    "            if unexplored:\n",
    "                child = unexplored.pop()\n",
    "                path.append(child)\n",
    "                self.iterations += 1\n",
    "                return path\n",
    "            sudoku_grid = self._action_selection(sudoku_grid)\n",
    "\n",
    "    def _simulate(self, sudoku_grid):\n",
    "        while not sudoku_grid.is_terminal():\n",
    "            self.iterations += 1\n",
    "            sudoku_grid = sudoku_grid.find_random_child()\n",
    "        if sudoku_grid.grid.is_complete() and sudoku_grid.grid.is_correct():\n",
    "            self.sudoku_grid = sudoku_grid\n",
    "        return sudoku_grid.reward()\n",
    "\n",
    "    def _expand(self, sudoku_grid):\n",
    "        if sudoku_grid in self.children:\n",
    "            return None\n",
    "        self.iterations += 1\n",
    "        self.children[sudoku_grid] = sudoku_grid.find_children()\n",
    "\n",
    "    def _backpropagate(self, path, reward):\n",
    "        for sudoku_grid in reversed(path):\n",
    "            self.N[sudoku_grid] = self.N.get(sudoku_grid, 0) + 1\n",
    "            self.Q[sudoku_grid] = self.Q.get(sudoku_grid, 0) + reward\n",
    "\n",
    "    def _action_selection(self, sudoku_grid):\n",
    "\n",
    "        log_N_parent = log(self.N[sudoku_grid])\n",
    "\n",
    "        def uct(child):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            return self.Q[child] / self.N[child] + self.exploration_weight * \\\n",
    "                sqrt(log_N_parent / self.N[child])\n",
    "\n",
    "        return max(self.children[sudoku_grid], key=uct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-commodity",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir ci-dessous, le nombre d'itérations peut parfois exploser. De même que précédemment, le niveau de difficulté semble influencer de manière directe les performances de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Description des performances de l'algorithme MCTS\")\n",
    "axes[0].boxplot(df_iterations[\"MCTS\"])\n",
    "axes[0].set_title(\"Nombre d'itérations effectuées\")\n",
    "df_iterations[df_iterations['difficulty'] < 5].groupby(\"difficulty\")['MCTS'].apply(np.mean).plot.bar(rot=0)\n",
    "axes[1].set_title(\"Moyenne itérations effectuées par niveau de difficulté\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks([1], ['MCTS Algorithm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Analyse des performances de MCTS\")\n",
    "axes[0].bar(x=['Succès', 'Echec'],\n",
    "        height=[100 * (1 - df_solved_bool['MCTS'].mean()),\n",
    "                100 * df_solved_bool['MCTS'].mean()],\n",
    "       width=0.4)\n",
    "axes[0].set_title('Succès vs échecs de MCTS')\n",
    "df_solved_bool.groupby(\"difficulty\")['MCTS'].apply(np.mean).plot.bar(rot=0);\n",
    "axes[1].set_title(\"Taux d'échec en fonction de la difficulté\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-cinema",
   "metadata": {},
   "source": [
    "#### Conclusion des partie II et III:\n",
    "Parmi les deux algorithmes vus précédemment, l'un a un taux d'échec très élevé (DeepIterativeSolver avec $40 \\%$), l'autre a un taux d'échec plus faible (MCTS avec $20 \\%$), mais au prix d'un nombre d'itérations beaucoup plus élevé pour MCTS que pour DeepIterativeSolver, qui a un nombre d'itérations constant et très faible.\n",
    "\n",
    "Aucun de ces algorithmes n'est satisfaisant, et nous allons essayer dans la partie suivante de créer un algorithme tirant parti des deux méthodes précédentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-invitation",
   "metadata": {},
   "source": [
    "<a id='partie_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-massachusetts",
   "metadata": {},
   "source": [
    "## Partie IV: Alpha Sudoku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-flour",
   "metadata": {},
   "source": [
    "Dans cette partie, je reprends les idées de la partie II et de la partie III, et les utilise dans un cadre unifié similaire à AlphaGo [[5]](#bibliography).\n",
    "\n",
    "En effet, la structure d'AlphaSudoku est très similaire à MCTS. De plus, je réutilise le réseau entraîné dans la partie II comme _rollout policy_ (je choisis les actions en me basant uniquement sur ce réseau), et utilise les probabilités calculées à partir de ce réseau pour la _tree policy_. En effet, pour cette dernière, et comme dans le cas d'AlphaGo je choisis l'action maximisant:\n",
    "\n",
    "$$argmax \\left(Q(s, a) + w * \\frac{P(s, a)}{1 + N(s, a))}\\right)$$\n",
    "\n",
    "où $w$ est le poids accordé à l'exploration, $Q(s, a)$ est la valeur associée à l'action $a$ (à la grille $a$) à partir de l'état $s$ (la grille $s$), $P(s, a)$ sa probabilité calculée par le réseau et $N(s, a)$ le nombre de visites de cette action (grille) à partir de l'état considéré.\n",
    "\n",
    "De même que dans la partie III, j'utilise simplement le nombre de cellules non-vides pour évaluer les grilles finales, avec un facteur de discount égal à 1.\n",
    "\n",
    "Les différences par rapport à AlphaSudoku sont les suivantes:\n",
    "- Je ne réentraîne pas le réseau avec des \"parties\" jouées en utilisant ce réseau.\n",
    "- Je n'ai pas de value network, car j'utilise la fonction de reward très simple décrite dans la partie précédente.\n",
    "- J'utilise le réseau à la fois comme _SL policy_ (utilisé dans AlphaGo pour choisir les mouvements pour étendre l'arbre) et comme _rollout policy_. Cela ralentit l'algorithme (Alpha Go choisi un réseau beaucoup plus simple pour la rollout policy afin d'aller plus vite) mais je peux me le permettre étant donné la simplicité du Sudoku par rapport au jeu de Go.\n",
    "- Je n'ai pas tuné les hyperparamètres comme le nombre d'extensions des arbres considérés, que je fixe à 20, ou encore le poids d'exploration, que je fixe à $\\sqrt{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class SudokuGridAlpha(SudokuGrid):\n",
    "    \"\"\" Overides some functions of parent SudokuGrid.\n",
    "\n",
    "    Basically, just add changes relatively to probabilities\n",
    "    used instead of randomly picking elements. \"\"\"\n",
    "\n",
    "    def __init__(self, grid, model, proba_taken=0):\n",
    "        super().__init__(grid)\n",
    "        self.model = model\n",
    "        self.proba_taken = proba_taken\n",
    "        self.proba_dict = None\n",
    "\n",
    "    def find_random_child(self):\n",
    "        pos = self.grid.possibilities\n",
    "        min_nb_pos_ind = min([len(v) for v in pos.values()])\n",
    "\n",
    "        if min_nb_pos_ind > 1:\n",
    "            # only calculate proba if non trivial choice at hand\n",
    "            if self.proba_dict is None:\n",
    "                self.proba_dict = self._predict_probas()\n",
    "            selected_action = max(self.proba_dict, key=self.proba_dict.get)\n",
    "            child = self.take_action(selected_action[0],\n",
    "                                     selected_action[1],\n",
    "                                     max(self.proba_dict.values()))\n",
    "            return child\n",
    "\n",
    "        if len(pos) != 0:\n",
    "            pos_considered = []\n",
    "            for k, v in pos.items():\n",
    "                # just look at indeces with min pos\n",
    "                if len(v) == min_nb_pos_ind:\n",
    "                    pos_considered.append(k)\n",
    "            _index = np.random.choice(range(len(pos_considered)))\n",
    "            index = pos_considered[_index]\n",
    "            action = self.grid.possibilities[index][0]\n",
    "            return self.take_action(index, action, 1)\n",
    "        return None\n",
    "\n",
    "    def _predict_probas(self):\n",
    "        array_of_proba = self.model.predict(\n",
    "            custom_encoder(self.grid.grid)\n",
    "            )\n",
    "        proba_dict = {}\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if self.grid.grid[i, j] == 0:\n",
    "                    pos_at_index = self.grid.possibilities[(i, j)]\n",
    "                    if len(pos_at_index) == 1:\n",
    "                        proba_dict = {}\n",
    "                        proba_dict[((i, j), pos_at_index[0])] = 1\n",
    "                        return proba_dict\n",
    "                    for v in range(9):\n",
    "                        proba_dict[((i, j), v + 1)] = \\\n",
    "                            array_of_proba[0, v, i, j]\n",
    "\n",
    "        return proba_dict\n",
    "\n",
    "    def find_children(self):\n",
    "        if self.is_terminal():\n",
    "            return set()\n",
    "        else:\n",
    "            if self.proba_dict is None:\n",
    "                self.proba_dict = self._predict_probas()\n",
    "            possible_moves = []\n",
    "            pos = self.grid.possibilities\n",
    "            min_nb_pos_ind = min([len(v) for v in pos.values()])\n",
    "            for index in pos:\n",
    "                # just look at indeces with min pos\n",
    "                if len(pos[index]) == min_nb_pos_ind:\n",
    "                    for value in pos[index]:\n",
    "                        possible_moves.append((index, value))\n",
    "                    # we only consider children on one cell --> sufficient\n",
    "                    return {self.take_action(a[0], a[1], self.proba_dict[a])\n",
    "                            for a in possible_moves}\n",
    "\n",
    "    def take_action(self, index, action, proba):\n",
    "        new_grid = SudokuGridAlpha(self.grid.grid.copy(),\n",
    "                                   self.model,\n",
    "                                   proba)\n",
    "        new_grid.grid.fill_cell(*index, action)\n",
    "        return new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "class AlphaSudoku(MCTS):\n",
    "    \"\"\" Monte Carlo Tree Search for Sudoku game.\n",
    "\n",
    "    Terminal (leaf) nodes are actions that lead to an incorrect\n",
    "    sudoku grid (with 2 same value on one line for example).\n",
    "    The value of a leaf node will be the number of cells filled.\n",
    "\n",
    "    The policy to choose random actions is a convolutional network\n",
    "    trained on 1 million sudoku games. \"\"\"\n",
    "\n",
    "    def __init__(self, sudoku_grid, max_iterations=10000,\n",
    "                 pathnet='policy_network',\n",
    "                 model=None, exploration_weight=2, max_depth_tree=20):\n",
    "\n",
    "        \"\"\" Sudoku Grid : either SudokuGridAlpha with model initialised,\n",
    "        or numpy array. If it is a numpy array, pathnet or directly model must\n",
    "        be provided. \"\"\"\n",
    "\n",
    "        if isinstance(sudoku_grid, np.ndarray):\n",
    "            if model is None:\n",
    "                model = load_model(pathnet)\n",
    "            sudoku_grid = SudokuGridAlpha(sudoku_grid, model)\n",
    "        super().__init__(sudoku_grid, exploration_weight, max_depth_tree,\n",
    "                         max_iterations)\n",
    "        self.probas = {}\n",
    "\n",
    "    def _action_selection(self, sudoku_grid):\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(child in self.children\n",
    "                   for child in self.children[sudoku_grid])\n",
    "\n",
    "        def to_maximise(child):\n",
    "            \"\"\" Function to minimize described in original alphaGo paper. \"\"\"\n",
    "            return self.Q[child] / self.N[child] + child.proba_taken / \\\n",
    "                (1 + self.N[child])\n",
    "\n",
    "        return max(self.children[sudoku_grid], key=to_maximise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-omaha",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir sur les figures suivantes, le taux de succès d'AlphaSudoku semble très encourageant, avec $3 \\%$ d'échecs. \n",
    "\n",
    "La difficulté semble influencer sur le taux d'échec, car sur les grilles les plus simples, cet algorithme semble se tromper dans moins de $2 \\%$ des cas en moyenne, contre $7 \\%$ environ sur les grilles les plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Analyse des performances d'AlphaSudoku\")\n",
    "axes[0].bar(x=['Succès', 'Echec'],\n",
    "        height=[100 * (1 - df_solved_bool['AlphaSudoku'].mean()),\n",
    "                100 * df_solved_bool['AlphaSudoku'].mean()],\n",
    "       width=0.4)\n",
    "axes[0].set_title(\"Succès vs échecs d'AlphaSudoku\")\n",
    "df_solved_bool.groupby(\"difficulty\")['AlphaSudoku'].apply(np.mean).plot.bar(rot=0);\n",
    "axes[1].set_title(\"Taux d'échec en fonction de la difficulté\")\n",
    "plt.sca(axes[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-effectiveness",
   "metadata": {},
   "source": [
    "Mais qu'en est-il des performances en termes d'itérations ?\n",
    "\n",
    "Comme nous pouvons le voir sur les figures suivantes, elles semblent encore très raisonnables ! En effet, la grande majorité des problèmes requièrent moins de 500 itérations, avec des maxima vers 3000.\n",
    "\n",
    "Mais passons à la partie suivante pour une meilleure comparaison des algorithmes vus jusqu'à maintenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Description des performances de l'algorithme AlphaSudoku\")\n",
    "axes[0].boxplot(df_iterations[\"AlphaSudoku\"])\n",
    "axes[0].set_title(\"Nombre d'itérations effectuées\")\n",
    "df_iterations[df_iterations['difficulty'] < 5].groupby(\"difficulty\")['AlphaSudoku'].apply(np.mean).plot.bar(rot=0)\n",
    "axes[1].set_title(\"Moyenne itérations effectuées par niveau de difficulté\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks([1], ['AlphaSudoku Algorithm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-inside",
   "metadata": {},
   "source": [
    "<a id='partie_5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-belize",
   "metadata": {},
   "source": [
    "## Partie V: Comparaison, résultats\n",
    "\n",
    "#### Nombre d'itérations\n",
    "\n",
    "Commençons tout d'abord par nous intéresser au nombre d'itérations de nos algorithmes.\n",
    "\n",
    "Comme nous pouvons le voir ici, DeepIterativeSolver est beaucoup plus rapide (mais au prix de plus d'échecs comme nous le verrons juste après). Vient ensuite AlphaSudoku, loin devant Backtrack et MCTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Analyse des performances\")\n",
    "axes[0].boxplot(df_iterations[['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku']])\n",
    "axes[0].set_title(\"Nombre d'itérations\")\n",
    "axes[1].boxplot(df_iterations[['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku']])\n",
    "axes[1].set_title(\"Nombre d'itérations (zoom)\")\n",
    "axes[1].set_ylim((0, 3000))\n",
    "plt.setp(axes, xticks=[1, 2, 3, 4], xticklabels=['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-jones",
   "metadata": {},
   "source": [
    "Concernant le nombre d'itérations par niveau de difficulté, nous pouvons voir que **AlphaSudoku** et \n",
    "**MCTS** semblent moins sensibles au niveau de difficulté des grilles, et ont ainsi une durée relativement constante d'exécution sur les différents types de problème (en moyenne bien entendu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iterations[df_iterations['difficulty'] < 5].groupby(\"difficulty\")\\\n",
    "    [['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku']].apply(np.mean).plot.bar(rot=0, title=\"Nombre moyen d'itérations par niveau de difficulté\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-spiritual",
   "metadata": {},
   "source": [
    "#### Taux d'échec des algorithmes\n",
    "\n",
    "De même que précédemment, comparons les algorithmes globalement puis plus en détail en fonction de la difficulté des problèmes considérés. Encore une fois, la comparaison joue clairement en faveur d'AlphaSudoku pour les méthodes probabilistes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-borough",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "fig.suptitle(\"Description des performances de l'algorithme AlphaSudoku\")\n",
    "axes[0].bar(['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku'], \n",
    "            df_solved_bool[['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku']].mean())\n",
    "axes[0].set_title(\"Taux d'échec global\")\n",
    "df_diff_solved = df_solved_bool.groupby('difficulty')[['Backtrack', 'DeepIterativeSolver', 'MCTS', 'AlphaSudoku']].mean()\n",
    "df_diff_solved.plot.bar(ax=axes[1], rot=0)\n",
    "axes[1].set_title(\"Taux d'échec par niveau de difficulté\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-protein",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-adrian",
   "metadata": {},
   "source": [
    "Le jeu de Sudoku se résout très bien par l'algorithme de Backtrack, qui fournit dans un temps raisonnable une solution de manière certaine. Cependant, nous avons pu voir dans ce projet que des méthodes probabilistes peuvent donner des résultats également très bons en termes d'itérations, au prix d'une perte en termes de succès. Dans le cas d'AlphaSudoku, cette perte est faible, et pourrait sans doute être améliorée par une optimisation assez simple.\n",
    "\n",
    "En effet, comme j'ai déjà pu le mentionner, le fonction de reward est extrêmement simple et il est vraisemblable qu'elle puisse être améliorée (par exemple : 2 * nbcellulesnonvides / 81 - 1 afin de pénaliser les grilles s'arrêtant trop tôt, mais beaucoup d'autres possibilités pourraient être envisagées). De plus, je n'ai pas essayé d'optimiser les autres paramètres des modèles comme le poids donné à l'exploration par exemple. Enfin, je pourrais tirer parti de la symétrie du problème en faisant prédire chaque grille 4 fois, en faisant une rotation à chaque fois et en faisant voter les résultats obtenus (cela ralentirait l'algorithme mais pourrait donner de meilleurs résultats).\n",
    "\n",
    "Il pourrait aussi être intéressant de comparer ces algorithmes en termes de temps de calcul. Si j'avais eu plus de temps, j'aurai cherché à optimiser le plus possible les algorithmes afin de pouvoir les comparer en ces termes. Mais même ainsi, comme j'ai pu le dire en introduction, les performances seraient dépendantes des machines plus que des algorithmes en eux-mêmes, ce qui m'a fait opter pour une comparaison en termes d'itérations.\n",
    "\n",
    "Enfin, j'aurais aimé comparer ces algorithmes sur des grilles 16\\*16 et non plus seulement 9\\*9. Cela serait sans doute très intéressant car plus la dimension augmente, plus l'algorithme BackTrack prendra du temps à s'exécuter, alors qu'un algorithme comme AlphaSudoku semble moins impacté par la difficulté des problèmes. En revanche, l'entraînement serait alors un véritable challenge car il est peu probable que des millions de grilles 16\\*16 soient disponibles aussi facilement que celles de taille 9\\*9.\n",
    "\n",
    "Ainsi, pour résoudre ce dernier problème, il serait intéressant de développer un algorithme apprenant seul à résoudre des grilles vides par exemple. Sans doute que cette approche serait plus efficace que l'algorithme Backtrack afin de créer de nouvelles grilles 16\\*16! AlphaSudoku Zéro a de l'avenir ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-thompson",
   "metadata": {},
   "source": [
    "<a id='bibliography'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-orientation",
   "metadata": {},
   "source": [
    "## Bibliographie\n",
    "\n",
    "[1] https://fr.wikipedia.org/wiki/Sudoku\n",
    "\n",
    "[2] Jean-Paul Delahaye; <ins>_The Science behind Sudoku_</ins>, Scientific American, Vol. 294, No. 6, pp. 80–\n",
    "87, 2006. ([paper](http://www.cs.virginia.edu/~robins/The_Science_Behind_SudoKu.pdf))\n",
    "\n",
    "[3] Gary McGuire, Bastian Tugemann, Gilles Civario ; <ins>_There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues Problem_</ins> January 2012, Experimental Mathematics 23. ([paper](https://arxiv.org/abs/1201.0749))\n",
    "\n",
    "[4] Donald Knuth ; <ins>_Dancing Links_</ins> Perspectives in Computer Science, 2000, 187--214 ; ([paper](https://arxiv.org/abs/cs/0011047))\n",
    "\n",
    "[5] Silver, D., Huang, A., Maddison, C. et al. <ins>_Mastering the game of Go with Deep Neural Networks & Tree Search_ </ins>  Nature 529, 484–489 (2016). ([paper](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
